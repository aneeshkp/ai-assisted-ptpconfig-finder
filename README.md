# ai-assisted-ptpconfig-finder



use Ollama instead of llama-cpp for local LLM responses!


    Install Ollama:

curl -fsSL https://ollama.com/install.sh | sh

    Pull a model (e.g., Mistral):

ollama pull mistral

    Run your script:

python ptp_config_assistant.py
